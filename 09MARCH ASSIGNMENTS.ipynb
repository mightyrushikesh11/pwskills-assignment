{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e703be37-1b72-4831-9bea-59603b362f17",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example.\n",
    "\n",
    "Ans.Probability Mass Function (PMF) and Probability Density Function (PDF) are two ways of describing the probability distribution of a random variable.\n",
    "\n",
    "The PMF is a function that assigns a probability to each possible value that a discrete random variable can take. In other words, the PMF gives the probability of a specific outcome occurring. For example, suppose we have a fair six-sided die. The PMF of the die would be:\n",
    "\n",
    "PMF(X = x) = 1/6, for x = 1,2,3,4,5,6\n",
    "\n",
    "This means that each outcome (1,2,3,4,5,6) has an equal probability of occurring, which is 1/6.\n",
    "\n",
    "The PDF, on the other hand, is used to describe the probability distribution of a continuous random variable. It gives the probability density at each point along the range of possible values. The probability density at a given point does not directly give the probability of that point, but rather the relative likelihood of the random variable taking a value close to that point.\n",
    "\n",
    "For example, suppose we have a normally distributed random variable X with mean μ = 0 and standard deviation σ = 1. The PDF of X is:\n",
    "\n",
    "f(x) = (1/(sqrt(2π)σ)) * exp(-(x-μ)²/(2σ²))\n",
    "\n",
    "The PDF tells us the likelihood of observing different values of X. For example, we can use the PDF to calculate the probability of X being between -1 and 1:\n",
    "\n",
    "P(-1 < X < 1) = ∫_-1^1 f(x)dx\n",
    "\n",
    "The PDF gives us the relative likelihood of different values of X, but we need to integrate over the range we're interested in to get an actual probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9df86-e2bc-4476-b3c1-26457b67af12",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "\n",
    "Ans.The Cumulative Density Function (CDF) is a function that describes the probability that a random variable takes on a value less than or equal to a specific value. It is often denoted as F(x) for a given value of x.\n",
    "\n",
    "The CDF is useful because it allows us to calculate probabilities for a continuous random variable in a way that is similar to the way we calculate probabilities for a discrete random variable using the Probability Mass Function (PMF). The CDF is defined for both continuous and discrete random variables.\n",
    "\n",
    "Here's an example of a CDF:\n",
    "\n",
    "Suppose we have a random variable X that represents the weight of a randomly selected apple from an orchard. Let's say that the CDF of X is:\n",
    "\n",
    "F(x) = 0, for x < 0\n",
    "F(x) = x/10, for 0 <= x < 10\n",
    "F(x) = 1, for x >= 10\n",
    "\n",
    "This means that if we want to know the probability that a randomly selected apple weighs less than or equal to 6 ounces, we would calculate:\n",
    "\n",
    "F(6) = 6/10 = 0.6\n",
    "\n",
    "This tells us that there is a 60% chance that a randomly selected apple weighs less than or equal to 6 ounces.\n",
    "\n",
    "The CDF is used for a variety of purposes, including calculating probabilities for a continuous random variable and comparing the probability distribution of different random variables. The CDF can also be used to generate other useful functions, such as the Probability Density Function (PDF) and the Quantile Functi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a96d38-f46f-459f-ae9f-e8aba3de13d6",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "Ans. The normal distribution, also known as the Gaussian distribution, is a common probability distribution that is used to model many real-world situations. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Heights of people in a population\n",
    "Weights of objects produced in a factory\n",
    "Test scores of a large group of students\n",
    "Errors in measurements or observations\n",
    "IQ scores in a population\n",
    "The parameters of the normal distribution are the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, while the standard deviation represents the spread or variability of the distribution.\n",
    "\n",
    "The shape of the normal distribution is symmetric and bell-shaped, with the highest point of the curve located at the mean. The spread of the distribution is determined by the value of the standard deviation, with larger values of σ resulting in a wider and flatter curve, and smaller values of σ resulting in a narrower and taller curve.\n",
    "\n",
    "In particular, 68% of the data falls within one standard deviation of the mean, 95% falls within two standard deviations of the mean, and 99.7% falls within three standard deviations of the mean. This property of the normal distribution is known as the empirical rule or the 68-95-99.7 rule.\n",
    "\n",
    "Knowing the parameters of the normal distribution allows us to calculate probabilities of observing different values of a random variable, which can be useful for making predictions or drawing conclusions based on data. The normal distribution is widely used in statistics, data analysis, and many other fields due to its simplicity and versatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b86d7eb-b9d5-49fd-ac33-079af58a747f",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a86aff-ad08-4397-96f9-dee81e90afa4",
   "metadata": {},
   "source": [
    "Ans.The normal distribution, also known as the Gaussian distribution, is one of the most important probability distributions in statistics and data analysis. Here are some reasons why the normal distribution is so important:\n",
    "\n",
    "Many natural phenomena follow a normal distribution: The normal distribution often arises as a result of many small, independent random variables contributing to an overall outcome. This makes it a useful model for a wide range of natural phenomena, such as the distribution of heights and weights in a population, the variation of stock prices over time, and the distribution of IQ scores in a population.\n",
    "\n",
    "Central Limit Theorem: The central limit theorem states that the sum or average of a large number of independent and identically distributed random variables will tend to follow a normal distribution, regardless of the underlying distribution of the individual variables. This makes the normal distribution a valuable tool for hypothesis testing, confidence intervals, and other statistical analyses.\n",
    "\n",
    "Ease of use: The normal distribution is mathematically simple and easy to work with, making it a convenient choice for many applications. Its simplicity also allows us to make accurate predictions and perform reliable statistical inference based on limited data.\n",
    "\n",
    "Here are some real-life examples where the normal distribution can be observed:\n",
    "\n",
    "Heights of people in a population: The height distribution of a large group of people typically follows a normal distribution, with the majority of people clustered around the mean height.\n",
    "\n",
    "Test scores of a large group of students: The distribution of test scores among a large group of students is often close to normal, with the majority of students scoring around the average score.\n",
    "\n",
    "The weight of produce: The weight of a large number of apples or oranges in a batch often follows a normal distribution, with most of the fruit having a weight close to the mean weight.\n",
    "\n",
    "The distribution of body temperatures: The distribution of body temperatures in a healthy population is normally distributed, with the majority of people having a temperature close to the mean.\n",
    "\n",
    "IQ scores in a population: The distribution of IQ scores in a population is normally distributed, with most people having an IQ score close to the mean score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa868699-635d-4c9d-b793-a4095be97795",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75487472-c1d2-4161-9d96-74ce2cb53889",
   "metadata": {},
   "source": [
    "Ans.The Bernoulli distribution is a probability distribution that models the outcomes of a single binary event, which can either be a success or a failure. The distribution is named after Swiss mathematician Jacob Bernoulli, who introduced it in his book \"Ars Conjectandi\" in 1713.\n",
    "\n",
    "In the Bernoulli distribution, the parameter p represents the probability of a success, and the probability of a failure is 1-p. The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "P(X = x) = p^x * (1-p)^(1-x)\n",
    "\n",
    "where x can only take on the values of 0 or 1.\n",
    "\n",
    "Example: The outcome of a coin toss can be modeled by a Bernoulli distribution, where a \"heads\" is considered a success (x = 1) and a \"tails\" is considered a failure (x = 0). If the probability of getting a heads is p = 0.5, then the PMF of the Bernoulli distribution would be:\n",
    "\n",
    "P(X = 0) = 0.5^0 * 0.5^(1-0) = 0.5\n",
    "P(X = 1) = 0.5^1 * 0.5^(1-1) = 0.5\n",
    "\n",
    "The Bernoulli distribution is a special case of the binomial distribution, which models the number of successes in a fixed number of independent trials. The main difference between the Bernoulli and binomial distributions is that the Bernoulli distribution models a single trial, while the binomial distribution models multiple, independent trials.\n",
    "\n",
    "The binomial distribution has two parameters: n, the number of trials, and p, the probability of success in each trial. The probability mass function of the binomial distribution is:\n",
    "\n",
    "P(X = k) = n! / (k! * (n-k)!) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where k is the number of successes and can take on any value from 0 to n.\n",
    "\n",
    "Example: The number of heads obtained in 10 tosses of a fair coin can be modeled by a binomial distribution, where n = 10 and p = 0.5. The probability of obtaining k heads can be calculated using the binomial PMF formula.\n",
    "\n",
    "Overall, the Bernoulli distribution can be seen as a special case of the binomial distribution where the number of trials is fixed at 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fcf8aa-90cf-4707-b86a-45fc309caf3e",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a721107-3b52-46bf-b5be-21d817ae5d95",
   "metadata": {},
   "source": [
    "Ans.Given:\n",
    "\n",
    "Mean (μ) = 50\n",
    "Standard deviation (σ) = 10\n",
    "\n",
    "We need to find the probability that a randomly selected observation will be greater than 60.\n",
    "\n",
    "To solve this problem, we need to use the standard normal distribution and convert the given data into z-scores using the formula:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the observed value, μ is the mean and σ is the standard deviation.\n",
    "\n",
    "In this case, we want to find the probability of an observation greater than 60. So, we first convert 60 into a z-score:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "Now, we need to find the area under the standard normal distribution curve to the right of z = 1. We can do this using a standard normal distribution table or a calculator.\n",
    "\n",
    "Using a standard normal distribution table, we find that the probability of a z-score greater than 1 is 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60 is 0.1587 or approximately 16%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79056258-be65-485b-85fc-a3a5d19a33d3",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2b64b-3aab-404c-8a78-30885002998b",
   "metadata": {},
   "source": [
    "Ans.Uniform distribution is a probability distribution where all outcomes have an equal probability of occurring. This means that every value within a given range is equally likely to occur, and there are no outcomes that are more or less likely than others.\n",
    "\n",
    "The uniform distribution is often used to model situations where every outcome has an equal chance of occurring, such as rolling a fair die, selecting a random number from a range of values, or picking a card from a well-shuffled deck.\n",
    "\n",
    "The probability density function (PDF) of the uniform distribution is given by:\n",
    "\n",
    "f(x) = 1 / (b - a)\n",
    "\n",
    "where a is the minimum value in the range and b is the maximum value in the range.\n",
    "\n",
    "For example, suppose we have a six-sided die that is fair, meaning that each side has an equal chance of coming up. The possible outcomes are 1, 2, 3, 4, 5, and 6, and each outcome has a probability of 1/6. This can be modeled using a discrete uniform distribution, where the probability of each outcome is the same.\n",
    "\n",
    "Alternatively, suppose we have a random number generator that generates a number between 0 and 1 with equal probability. The range of possible outcomes is [0, 1], and each value in this range has a probability of 1/(1-0) = 1. This can be modeled using a continuous uniform distribution, where the PDF is f(x) = 1 for 0 <= x <= 1 and f(x) = 0 for x < 0 or x > 1.\n",
    "\n",
    "In summary, the uniform distribution is a simple and useful probability distribution that models situations where all outcomes have an equal probability of occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58405d2f-4f1a-4c98-910f-c871d5a07ecb",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aefb0-ecb0-4a41-8344-93189c173d05",
   "metadata": {},
   "source": [
    "Ans.A z-score, also known as a standard score, is a measure of how many standard deviations an observed value is from the mean of a distribution. It tells us how far a data point is from the mean in terms of standard deviations.\n",
    "\n",
    "The formula for calculating the z-score of a data point x is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where μ is the mean of the distribution and σ is the standard deviation of the distribution.\n",
    "\n",
    "The importance of the z-score lies in its ability to standardize data from different distributions and scales, allowing us to compare and analyze data more easily. Specifically, the z-score can be used to:\n",
    "\n",
    "Determine the relative position of an observation within a distribution.\n",
    "Compare observations from different distributions with different units or scales.\n",
    "Determine the probability of an observation occurring, given its z-score and assuming a normal distribution.\n",
    "For example, suppose we have two distributions with different means and standard deviations. We can use the z-score to compare a data point from one distribution to the other, by standardizing the data points from both distributions to a common scale.\n",
    "\n",
    "In summary, the z-score is an important statistical tool that allows us to compare and analyze data from different distributions and scales. It is commonly used in hypothesis testing, statistical inference, and other applications of statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060206fd-99cb-4d3a-92c7-2b27a5b0ba30",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab4683-b5da-44fd-83f6-716c0e996e84",
   "metadata": {},
   "source": [
    "Ans.The Central Limit Theorem (CLT) is a fundamental result in statistics that describes the behavior of the means of a large number of independent, identically distributed random variables, regardless of their underlying distribution. Specifically, it states that as the sample size n increases, the distribution of the sample means approaches a normal distribution, with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of n.\n",
    "\n",
    "The significance of the Central Limit Theorem lies in its ability to provide a foundation for statistical inference, hypothesis testing, and confidence interval estimation. It allows us to make inferences about population parameters based on a sample of data, even when the underlying population distribution is unknown or non-normal.\n",
    "\n",
    "Some key implications of the Central Limit Theorem include:\n",
    "\n",
    "The means of large samples from any population will be approximately normally distributed, regardless of the shape of the population distribution.\n",
    "The sample mean is an unbiased estimator of the population mean, and its distribution becomes more concentrated around the population mean as the sample size increases.\n",
    "The standard error of the sample mean decreases as the sample size increases, indicating that larger samples provide more precise estimates of the population mean.\n",
    "In summary, the Central Limit Theorem is a fundamental concept in statistics that describes the behavior of the means of a large number of independent, identically distributed random variables. It is important because it provides a foundation for statistical inference and allows us to make inferences about population parameters based on a sample of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad39d88d-71e2-4e13-9f38-be8611713c7c",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37cafd-803b-4174-b308-b527f405ff54",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental result in statistics that describes the behavior of the means of a large number of independent, identically distributed random variables. The theorem makes certain assumptions about the underlying population distribution, sample size, and independence of the random variables. The assumptions of the Central Limit Theorem are:\n",
    "\n",
    "The random variables are independent and identically distributed (i.i.d.).\n",
    "The population distribution has a finite mean (μ) and a finite standard deviation (σ).\n",
    "The sample size is sufficiently large (usually n > 30).\n",
    "These assumptions are important because they ensure that the sample means are approximately normally distributed, regardless of the underlying population distribution. Violating any of these assumptions may lead to biased or incorrect results.\n",
    "\n",
    "In addition to these assumptions, there are some other factors to consider when applying the Central Limit Theorem. For example, the theorem assumes that the random variables are drawn from a single population, and that the samples are drawn randomly and without replacement. If these conditions are not met, the Central Limit Theorem may not apply, and alternative methods may need to be used.\n",
    "\n",
    "Overall, the Central Limit Theorem is a powerful tool in statistics that can help us make inferences about population parameters based on a sample of data, but it is important to understand its assumptions and limitations in order to use it correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
